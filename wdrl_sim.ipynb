{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted doubly robust learning: A simulation\n",
    "\n",
    "This notebook reviews _weighted doubly robust learning_, a technique by Zhan, et al., to recover causal effects when different treatments are confounded. For example, a company may apply several promotions to customers during a large advertising campaign. This method is akin to Shapley values to isolate the true conditional average treatment effect (CATE) of each treatment.\n",
    "\n",
    "I set up a simulation very similar to that in the paper to demonstrate the method's effectiveness.\n",
    "\n",
    "**Reference**\n",
    "\n",
    "Zhan, B., Liu, C., Li, Y. and Wu, C., 2024. Weighted doubly robust learning: An uplift modeling technique for estimating mixed treatments' effect. _Decision Support Systems_, 176, p.114060. https://doi.org/10.1016/j.dss.2023.114060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "np.random.seed(1804)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up simulation\n",
    "\n",
    "Generate a dataset of 10 thousand observations, with 40 features, and three treatments (A, B, C). Only the first few features will have any effect on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_units = 10_000\n",
    "n_features = 40\n",
    "\n",
    "# Generate covariates (X variables)\n",
    "X = np.random.normal(size=(n_units, n_features))\n",
    "X_columns = [f'X{i+1}' for i in range(n_features)]\n",
    "df = pd.DataFrame(X, columns=X_columns)\n",
    "\n",
    "# Treatment assignment probabilities (influenced by covariates)\n",
    "p_TA = 1 / (1 + np.exp(-X[:, 0] + 0.5 * X[:, 1]))  # Sigmoid function\n",
    "p_TB = 1 / (1 + np.exp(-X[:, 2] - 0.3 * X[:, 3]))\n",
    "p_TC = 1 / (1 + np.exp(X[:, 4] + 0.7 * X[:, 5]))\n",
    "\n",
    "# Assign treatments (discrete binary values, independent but influenced by X)\n",
    "df['TA'] = np.random.binomial(1, p_TA)\n",
    "df['TB'] = np.random.binomial(1, p_TB)\n",
    "df['TC'] = np.random.binomial(1, p_TC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The treatment effects are directly set below. Ideally, the result of this algorithm will show effects very similar to these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment effects\n",
    "effect_TA = 2.0\n",
    "effect_TB = -1.5\n",
    "effect_TC = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0 -0.214325 -0.553342 -0.571716 -0.821458 -0.976144 -0.287905 -1.255918   \n",
      "1 -1.093172 -1.085448  0.735668  1.975224  1.032347  0.126879  1.747678   \n",
      "2  0.846787  0.031084  1.183459 -1.463539 -0.679032  0.661826  0.764342   \n",
      "3  1.299280  1.335320  0.326247  1.134321 -0.204174 -0.715236  0.408855   \n",
      "4 -0.433620  0.538348 -0.528164  2.055443 -0.392551 -1.185478 -0.465252   \n",
      "\n",
      "         X8        X9       X10  ...       X36       X37       X38       X39  \\\n",
      "0 -2.048305 -0.838211  0.783283  ...  0.706155  1.044931  0.162699  0.368533   \n",
      "1  0.580236  0.640855 -0.362036  ...  0.123426  0.913608  0.493342  1.291280   \n",
      "2  0.281379  0.042616 -0.798705  ... -0.080010 -1.334000  0.541168  0.492100   \n",
      "3  0.064756 -0.881248  0.934774  ... -0.052189  0.383240 -0.188075  0.203655   \n",
      "4  1.790214  1.176643 -0.138594  ... -1.685168 -1.247496 -1.884123  1.194776   \n",
      "\n",
      "        X40  TA  TB  TC         y    t  \n",
      "0 -0.251308   0   0   0 -1.168181    0  \n",
      "1  1.676777   0   1   0 -0.615659    B  \n",
      "2 -0.217053   1   1   1  3.869084  ABC  \n",
      "3 -0.195231   1   1   1  4.061402  ABC  \n",
      "4  1.030321   1   0   0  2.013415    A  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate outcome Y (additive model)\n",
    "noise = np.random.normal(0, 1, n_units)\n",
    "df['y'] = (\n",
    "    effect_TA * df['TA'] +\n",
    "    effect_TB * df['TB'] +\n",
    "    effect_TC * df['TC'] +\n",
    "    0.3 * X[:, 6] - 0.2 * X[:, 7] + 0.5 * X[:, 8] +  # Covariate effects\n",
    "    noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a label listing all treatments applied to an observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0 -0.214325 -0.553342 -0.571716 -0.821458 -0.976144 -0.287905 -1.255918   \n",
      "1 -1.093172 -1.085448  0.735668  1.975224  1.032347  0.126879  1.747678   \n",
      "2  0.846787  0.031084  1.183459 -1.463539 -0.679032  0.661826  0.764342   \n",
      "3  1.299280  1.335320  0.326247  1.134321 -0.204174 -0.715236  0.408855   \n",
      "4 -0.433620  0.538348 -0.528164  2.055443 -0.392551 -1.185478 -0.465252   \n",
      "\n",
      "         X8        X9       X10  ...       X36       X37       X38       X39  \\\n",
      "0 -2.048305 -0.838211  0.783283  ...  0.706155  1.044931  0.162699  0.368533   \n",
      "1  0.580236  0.640855 -0.362036  ...  0.123426  0.913608  0.493342  1.291280   \n",
      "2  0.281379  0.042616 -0.798705  ... -0.080010 -1.334000  0.541168  0.492100   \n",
      "3  0.064756 -0.881248  0.934774  ... -0.052189  0.383240 -0.188075  0.203655   \n",
      "4  1.790214  1.176643 -0.138594  ... -1.685168 -1.247496 -1.884123  1.194776   \n",
      "\n",
      "        X40  TA  TB  TC         y    t  \n",
      "0 -0.251308   0   0   0 -1.168181    0  \n",
      "1  1.676777   0   1   0 -0.615659    B  \n",
      "2 -0.217053   1   1   1  3.869084  ABC  \n",
      "3 -0.195231   1   1   1  4.061402  ABC  \n",
      "4  1.030321   1   0   0  2.013415    A  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a joined treatment column using letters\n",
    "def combine_treatments(row):\n",
    "    treatments = []\n",
    "    if row['TA'] == 1:\n",
    "        treatments.append('A')\n",
    "    if row['TB'] == 1:\n",
    "        treatments.append('B')\n",
    "    if row['TC'] == 1:\n",
    "        treatments.append('C')\n",
    "    return ''.join(treatments) if treatments else '0'\n",
    "\n",
    "# Apply the function to each row and create a new column 't'\n",
    "df['t'] = df.apply(combine_treatments, axis=1)\n",
    "\n",
    "# Preview\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "df_train = df.iloc[:7000]\n",
    "df_test = df.iloc[7000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows that all possible treatment combinations are present, and occurs in equal numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.12757142857142856,\n",
       " 'B': 0.12742857142857142,\n",
       " 'AC': 0.127,\n",
       " 'BC': 0.12571428571428572,\n",
       " 'ABC': 0.125,\n",
       " 'C': 0.12414285714285714,\n",
       " 'AB': 0.12214285714285714,\n",
       " '0': 0.121}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create treatment weights\n",
    "treatment_prob = df_train['t'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "treatment_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', 'A', 'B', 'C', 'AB', 'AC', 'BC', 'ABC']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TREATMENTS = ['A', 'B', 'C']\n",
    "\n",
    "all_combinations = list(chain.from_iterable(combinations(TREATMENTS, r) for r in range(len(TREATMENTS) + 1)))\n",
    "all_combinations = [''.join(i) for i in all_combinations]\n",
    "\n",
    "C = ['0' if i == '' else i for i in all_combinations]\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform WDRL\n",
    "\n",
    "The functions below are the main implementation of WDRL. The ultimate results are printed below, and are very close to the treatment effect manually set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing treatment A...\n",
      "ATE for treatment A: 1.9316\n",
      "\n",
      "Processing treatment B...\n",
      "ATE for treatment B: -1.4757\n",
      "\n",
      "Processing treatment C...\n",
      "ATE for treatment C: 3.0026\n",
      "Final ATE results: {'A': np.float64(1.931633198660085), 'B': np.float64(-1.4756925591041896), 'C': np.float64(3.0026359906402273)}\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate propensity scores\n",
    "def calculate_propensity_scores(X, T):\n",
    "    model_t = LogisticRegression(penalty=None).fit(X, T)\n",
    "    return model_t.predict_proba(X)[:, 1]\n",
    "\n",
    "# Function to fit outcome models and compute doubly robust scores\n",
    "def calculate_doubly_robust_scores(X, y, T, ps):\n",
    "    m0 = LinearRegression().fit(X[T == 0], y[T == 0])\n",
    "    m1 = LinearRegression().fit(X[T == 1], y[T == 1])\n",
    "    \n",
    "    m0_hat = m0.predict(X)\n",
    "    m1_hat = m1.predict(X)\n",
    "    \n",
    "    y_dr_1 = m1_hat + (T * (y - m1_hat)) / ps\n",
    "    y_dr_0 = m0_hat + ((1 - T) * (y - m0_hat)) / (1 - ps)\n",
    "    \n",
    "    return y_dr_1 - y_dr_0\n",
    "\n",
    "# Function to compute weighted doubly robust scores\n",
    "def compute_weighted_dr_scores(dr_scores, treatment_prob):\n",
    "    valid_weights = {col: treatment_prob[col] for col in dr_scores.columns if col in treatment_prob}\n",
    "    weighted_sum = sum(dr_scores[col] * w for col, w in valid_weights.items())\n",
    "    return weighted_sum / sum(valid_weights.values())\n",
    "\n",
    "# Main loop to calculate ATE for each treatment\n",
    "def calculate_ate(df_train, C, treatment_prob, treatments):\n",
    "    treatment_cols = [f'T{t}' for t in treatments]\n",
    "    X = df_train.drop(columns=['y', 't'] + treatment_cols)\n",
    "    results = {}\n",
    "    \n",
    "    for treatment in treatments:\n",
    "        print(f\"\\nProcessing treatment {treatment}...\")\n",
    "        \n",
    "        # Split combinations into those with and without the current treatment\n",
    "        W_k = [comb for comb in C if treatment in comb]\n",
    "        S__k = [comb for comb in C if treatment not in comb]\n",
    "        \n",
    "        y_hat_dr_list = []\n",
    "        \n",
    "        for w_k, s__k in zip(W_k, S__k):\n",
    "            # Create treatment/control datasets\n",
    "            df_subset = df_train.query('t == @w_k | t == @s__k').copy()\n",
    "            df_subset['t_binary'] = np.where(df_subset['t'] == w_k, 1, 0)\n",
    "            \n",
    "            X_treated = df_subset.drop(columns=['y', 't', 't_binary'] + treatment_cols)\n",
    "            y_treated = df_subset['y']\n",
    "            T_treated = df_subset['t_binary']\n",
    "            \n",
    "            # Calculate propensity scores and doubly robust scores\n",
    "            ps = calculate_propensity_scores(X_treated, T_treated)\n",
    "            dr_scores = calculate_doubly_robust_scores(X_treated, y_treated, T_treated, ps)\n",
    "            \n",
    "            # Fit DR model on treatment group and apply it to the full dataset\n",
    "            dr_model = LinearRegression().fit(X_treated, dr_scores)\n",
    "            y_hat_dr = dr_model.predict(X)\n",
    "            y_hat_dr_list.append(y_hat_dr)\n",
    "        \n",
    "        # Aggregate results\n",
    "        dr_df = pd.DataFrame({w_k: scores for w_k, scores in zip(W_k, y_hat_dr_list)})\n",
    "        aggregated_dr_scores = compute_weighted_dr_scores(dr_df, treatment_prob)\n",
    "        \n",
    "        # Fit regression model to estimate ATE\n",
    "        ate_model = LinearRegression().fit(X, aggregated_dr_scores)\n",
    "        ate = np.mean(ate_model.predict(X))\n",
    "        \n",
    "        results[treatment] = ate\n",
    "        print(f\"ATE for treatment {treatment}: {ate:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (replace with actual data and variables)\n",
    "# df_train = ...\n",
    "treatments = ['A', 'B', 'C']  # List of all treatment labels\n",
    "# C = ...  # All possible combinations of treatments\n",
    "# treatment_prob = ...  # Dictionary with treatment probabilities\n",
    "\n",
    "ate_results = calculate_ate(df_train, C, treatment_prob, treatments)\n",
    "print(\"Final ATE results:\", ate_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
