{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted doubly robust learning: A extended simulation\n",
    "\n",
    "This simulation tests WDRL with five (imbalanced!) treatments, more sample, and more features. Some possible treatments are excluded as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "np.random.seed(1804)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100_000\n",
    "p = 100\n",
    "b = 5  # number of treatments\n",
    "\n",
    "X = np.random.uniform(0, 1, (n, p))\n",
    "\n",
    "sigma = 2\n",
    "error = np.random.normal(0, 1, n)\n",
    "\n",
    "# Define propensity function g*(k) for treatment assignment\n",
    "g_star = [.27, .17, .14, .27, .09]\n",
    "T = np.array([np.random.binomial(1, g_star[k], n) for k in range(b)]).T\n",
    "\n",
    "# baseline main effect e*(X_i)\n",
    "e_star = np.sin(np.pi * X[:, 0] * X[:, 1]) + 2 * (X[:, 2] - 0.5) ** 2 + X[:, 3] + 0.5 * X[:, 4]\n",
    "\n",
    "# treatment effect Ï„*(X_i)\n",
    "tau_star = (X[:, 0] + X[:, 1]) * 0.5\n",
    "# NOTE ^: Due to uniform distribution and this set up, the treatment effect of each will be about 0.5, the mean of each X\n",
    "\n",
    "Y = e_star + (np.sum(T - 0.5, axis=1)) * tau_star + sigma * error\n",
    "\n",
    "# Assemble into dataframe\n",
    "df = pd.DataFrame(X)\n",
    "df = df.rename(columns=lambda x: f\"x{x}\")\n",
    "\n",
    "treatment_df = pd.DataFrame(T, columns=['TA', 'TB', 'TC', 'TD', 'TE'])\n",
    "df = pd.concat([df, treatment_df], axis=1)\n",
    "\n",
    "df['y'] = Y\n",
    "\n",
    "# Create a joined treatment column using letters\n",
    "def combine_treatments(row):\n",
    "    treatments = []\n",
    "    if row['TA'] == 1:\n",
    "        treatments.append('A')\n",
    "    if row['TB'] == 1:\n",
    "        treatments.append('B')\n",
    "    if row['TC'] == 1:\n",
    "        treatments.append('C')\n",
    "    if row['TD'] == 1:\n",
    "        treatments.append('D')\n",
    "    if row['TE'] == 1:\n",
    "        treatments.append('E')\n",
    "    return ''.join(treatments) if treatments else '0'\n",
    "\n",
    "# Apply the function to each row and create a new column 't'\n",
    "df['t'] = df.apply(combine_treatments, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72389"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit to specific treatments\n",
    "df = df.query('t == \"0\" | t == \"ABD\" | t == \"ABCDE\" | t == \"AD\" | t == \"ACD\" | t == \"ABCD\" | t == \"ABDE\" | t == \"A\" | t == \"ADE\" | t == \"BCD\" | t == \"BD\" | t == \"ACDE\" | t == \"D\" | t == \"BCDE\" | t == \"BDE\" | t == \"DE\"')\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t\n",
       "0        34824\n",
       "AD        2049\n",
       "ABD        950\n",
       "ACD        783\n",
       "A          629\n",
       "ADE        472\n",
       "BCD        350\n",
       "BD         232\n",
       "D          215\n",
       "ABCD       166\n",
       "ABDE       100\n",
       "ACDE        84\n",
       "BCDE        26\n",
       "BDE         25\n",
       "ABCDE       24\n",
       "DE           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set number of samples for each treatment\n",
    "exact_sample_sizes = {'0': 36152,\n",
    "                      'ABD': 2759, \n",
    "                      'ABCDE': 2745,\n",
    "                      'AD': 2049,\n",
    "                      'ACD': 1891,\n",
    "                      'ABCD': 1643,\n",
    "                      'ABDE': 1204,\n",
    "                      'A': 629,\n",
    "                      'ADE': 472,\n",
    "                      'BCD': 350,\n",
    "                      'BD': 232,\n",
    "                      'ACDE': 229,\n",
    "                      'D': 215,\n",
    "                      'BCDE': 26,\n",
    "                      'BDE': 25,\n",
    "                      'DE': 3}\n",
    "\n",
    "assert sum(exact_sample_sizes.values()) <= len(df), \"Total sample size exceeds the number of rows in the dataframe.\"\n",
    "\n",
    "# Sample data from each group\n",
    "sampled_dfs = []\n",
    "for treatment, n_samples in exact_sample_sizes.items():\n",
    "    group = df[df['t'] == treatment]\n",
    "    # Ensure we don't sample more than available in the group\n",
    "    sampled_dfs.append(group.sample(n=min(len(group), n_samples), replace=False, random_state=42))\n",
    "\n",
    "# Combine sampled dataframes\n",
    "balanced_df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "balanced_df['t'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into train/test\n",
    "# df_train = df.iloc[:7000]\n",
    "# df_test = df.iloc[7000:]\n",
    "\n",
    "df_train = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create treatment weights\n",
    "treatment_prob = df_train['t'].value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREATMENTS = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "all_combinations = list(chain.from_iterable(combinations(TREATMENTS, r) for r in range(len(TREATMENTS) + 1)))\n",
    "all_combinations = [''.join(i) for i in all_combinations]\n",
    "\n",
    "C = ['0' if i == '' else i for i in all_combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing treatment A...\n",
      "['A', 'AD', 'ABD', 'ADE', 'ABCD', 'ABDE', 'ABCDE']\n",
      "['0', 'D', 'BD', 'DE', 'BCD', 'BDE', 'BCDE']\n",
      "A v. 0\n",
      "AD v. D\n",
      "ABD v. BD\n",
      "ADE v. DE\n",
      "Insufficient sample for ADE v. DE\n",
      "ABCD v. BCD\n",
      "ABDE v. BDE\n",
      "Insufficient sample for ABDE v. BDE\n",
      "ABCDE v. BCDE\n",
      "Insufficient sample for ABCDE v. BCDE\n",
      "ATE for treatment A: 0.4357\n",
      "\n",
      "Processing treatment B...\n",
      "['BD', 'ABD', 'BDE', 'ABCD', 'ABDE', 'ABCDE']\n",
      "['D', 'AD', 'DE', 'ACD', 'ADE', 'ACDE']\n",
      "BD v. D\n",
      "ABD v. AD\n",
      "BDE v. DE\n",
      "Insufficient sample for BDE v. DE\n",
      "ABCD v. ACD\n",
      "ABDE v. ADE\n",
      "ABCDE v. ACDE\n",
      "Insufficient sample for ABCDE v. ACDE\n",
      "ATE for treatment B: 1.3888\n",
      "\n",
      "Processing treatment C...\n",
      "['ACD', 'BCD', 'ABCD', 'ACDE', 'BCDE', 'ABCDE']\n",
      "['AD', 'BD', 'ABD', 'ADE', 'BDE', 'ABDE']\n",
      "ACD v. AD\n",
      "BCD v. BD\n",
      "ABCD v. ABD\n",
      "ACDE v. ADE\n",
      "BCDE v. BDE\n",
      "Insufficient sample for BCDE v. BDE\n",
      "ABCDE v. ABDE\n",
      "Insufficient sample for ABCDE v. ABDE\n",
      "ATE for treatment C: 0.5179\n",
      "\n",
      "Processing treatment D...\n",
      "['D', 'AD']\n",
      "['0', 'A']\n",
      "D v. 0\n",
      "AD v. A\n",
      "ATE for treatment D: 0.5124\n",
      "\n",
      "Processing treatment E...\n",
      "['DE', 'ADE', 'BDE', 'ABDE', 'ACDE', 'BCDE', 'ABCDE']\n",
      "['D', 'AD', 'BD', 'ABD', 'ACD', 'BCD', 'ABCD']\n",
      "DE v. D\n",
      "Insufficient sample for DE v. D\n",
      "ADE v. AD\n",
      "BDE v. BD\n",
      "Insufficient sample for BDE v. BD\n",
      "ABDE v. ABD\n",
      "ACDE v. ACD\n",
      "BCDE v. BCD\n",
      "Insufficient sample for BCDE v. BCD\n",
      "ABCDE v. ABCD\n",
      "Insufficient sample for ABCDE v. ABCD\n",
      "ATE for treatment E: 8.0068\n",
      "Final ATE results: {'A': np.float64(0.43566336149712215), 'B': np.float64(1.3887821582630853), 'C': np.float64(0.5178861664683317), 'D': np.float64(0.5124039550140255), 'E': np.float64(8.006757989955704)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to calculate propensity scores\n",
    "def calculate_propensity_scores(X, T):\n",
    "    model_t = make_pipeline(StandardScaler(), LogisticRegression(penalty=None))\n",
    "    model_t.fit(X, T)\n",
    "    preds = model_t.predict_proba(X)[:, 1]\n",
    "    return np.clip(preds, 0.01, 0.99)\n",
    "\n",
    "# Function to fit outcome models and compute doubly robust scores\n",
    "def calculate_doubly_robust_scores(X, y, T, ps):\n",
    "    m0 = LinearRegression().fit(X[T == 0], y[T == 0])\n",
    "    m1 = LinearRegression().fit(X[T == 1], y[T == 1])\n",
    "    \n",
    "    m0_hat = m0.predict(X)\n",
    "    m1_hat = m1.predict(X)\n",
    "\n",
    "    y_dr_1 = m1_hat + (T * (y - m1_hat)) / ps\n",
    "    y_dr_0 = m0_hat + ((1 - T) * (y - m0_hat)) / (1 - ps)\n",
    "    \n",
    "    return y_dr_1 - y_dr_0\n",
    "\n",
    "# Function to compute weighted doubly robust scores\n",
    "def compute_weighted_dr_scores(dr_scores, treatment_prob):\n",
    "    valid_weights = {col: treatment_prob[col] for col in dr_scores.columns if col in treatment_prob}\n",
    "    weighted_sum = sum(dr_scores[col] * w for col, w in valid_weights.items())\n",
    "    return weighted_sum / sum(valid_weights.values())\n",
    "\n",
    "# Main loop to calculate ATE for each treatment\n",
    "def calculate_ate(df_train, C, treatment_prob, treatments):\n",
    "    treatment_cols = [f'T{t}' for t in treatments]\n",
    "    X = df_train.drop(columns=['y', 't'] + treatment_cols)\n",
    "    results = {}\n",
    "    \n",
    "    for treatment in treatments:\n",
    "        print(f\"\\nProcessing treatment {treatment}...\")\n",
    "        \n",
    "        # Split combinations into those with and without the current treatment\n",
    "        W_k = [comb for comb in C if treatment in comb]\n",
    "        S__k = [comb for comb in C if treatment not in comb]\n",
    "\n",
    "        # Limit to existing pairs\n",
    "        W_k = [w for w, s in zip(W_k, S__k) if w in treatment_prob.keys() and s in treatment_prob.keys()]\n",
    "        S__k = [w.replace(treatment, '') for w in W_k]\n",
    "        S__k = ['0' if s == '' else s for s in S__k]\n",
    "\n",
    "        print(W_k)\n",
    "        print(S__k)\n",
    "\n",
    "        y_hat_dr_list = []\n",
    "        \n",
    "        for w_k, s__k in zip(W_k, S__k):\n",
    "\n",
    "            print(f'{w_k} v. {s__k}') \n",
    "\n",
    "            # Create treatment/control datasets\n",
    "            df_subset_w_k = df_train.query('t == @w_k').copy()\n",
    "            df_subset_s__k = df_train.query('t == @s__k').copy()\n",
    "\n",
    "            if len(df_subset_w_k) < 50 or len(df_subset_s__k) < 50:\n",
    "                print(f'Insufficient sample for {w_k} v. {s__k}')\n",
    "                continue\n",
    "            \n",
    "            df_subset = pd.concat([df_subset_w_k, df_subset_s__k])\n",
    "            df_subset['t_binary'] = np.where(df_subset['t'] == w_k, 1, 0)\n",
    "            \n",
    "            X_treated = df_subset.drop(columns=['y', 't', 't_binary'] + treatment_cols)\n",
    "            y_treated = df_subset['y']\n",
    "            T_treated = df_subset['t_binary']\n",
    "            \n",
    "            # Calculate propensity scores and doubly robust scores\n",
    "            ps = calculate_propensity_scores(X_treated, T_treated)\n",
    "            dr_scores = calculate_doubly_robust_scores(X_treated, y_treated, T_treated, ps)\n",
    "            \n",
    "            # Fit DR model on treatment group and apply it to the full dataset\n",
    "            dr_model = LinearRegression().fit(X_treated, dr_scores)\n",
    "            # dr_model = make_pipeline(StandardScaler(), Lasso(alpha=.01, tol=1e-3, max_iter=5000, random_state=42)).fit(X_treated, dr_scores)\n",
    "            y_hat_dr = dr_model.predict(X)\n",
    "            y_hat_dr_list.append(y_hat_dr)\n",
    "\n",
    "        # Aggregate results\n",
    "        dr_df = pd.DataFrame({w_k: scores for w_k, scores in zip(W_k, y_hat_dr_list)})\n",
    "\n",
    "        if len(dr_df) > 0:\n",
    "            # Fit regression model to estimate ATE\n",
    "            aggregated_dr_scores = compute_weighted_dr_scores(dr_df, treatment_prob)\n",
    "            ate_model = LinearRegression().fit(X, aggregated_dr_scores)\n",
    "            globals()['ate_model'] = ate_model\n",
    "            globals()['ate_preds'] = ate_model.predict(X)\n",
    "            globals()['ate_X'] = X\n",
    "            globals()['ate_y'] = aggregated_dr_scores\n",
    "            ate = np.mean(ate_model.predict(X))\n",
    "        else:\n",
    "            print(f'No sample for either {w_k} or {s__k}')\n",
    "            ate = np.NAN\n",
    "        \n",
    "        results[treatment] = ate\n",
    "        print(f\"ATE for treatment {treatment}: {ate:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (replace with actual data and variables)\n",
    "# df_train = ...\n",
    "treatments = ['A', 'B', 'C', 'D', 'E']  # List of all treatment labels\n",
    "# C = ...  # All possible combinations of treatments\n",
    "# treatment_prob = ...  # Dictionary with treatment probabilities\n",
    "\n",
    "ate_results = calculate_ate(df_train, C, treatment_prob, treatments)\n",
    "print(\"Final ATE results:\", ate_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ATE results: {'A': np.float64(0.43566336149712215), 'B': np.float64(1.3887821582630853), 'C': np.float64(0.5178861664683317), 'D': np.float64(0.5124039550140255), 'E': np.float64(8.006757989955704)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final ATE results:\", ate_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
